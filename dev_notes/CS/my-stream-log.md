

---

## 운영체제란?
+ 컴퓨터 자원의 총괄 관리자이자 추상화 계층이다
+ 하드웨어 자원을 관리한다
+ 사용자가 프로그램을 쉽게 실행할 수 있도록 추상화된 환경을 제공하는 소프트웨어

### 왜 필요한가?
| 상황 | 문제 | 운영체제가 하는 일 |
| --- | --- | --- |
| 여러 프로그램이 동시에 실행됨 | CPU, 메모리 자원 충돌 | 누구 먼저? -> *스케줄링* |
| 파일 저장함 | 하드디스크 구조가 복잡함 | 파일 이름, 폴더 등 -> *파일 시스템* |
| 키보드 누름 | 하드웨어가 전기신호만 줌 | OS가 받아서 프로그램에 *입출력 전달* |
| 메모리 부족 | 충돌 위험 | 각 프로그램에 *가상 메모리 공간 제공* |
| 위험한 명령어 | 프로그램이 다 실행하면 시스템 망가짐 | 사용자 모드 vs 커널 모드 로 구분 |

### 운영체제 구조도 (기억해야 하는 4요소)
```
[User] → [Application] → [System Call] → [OS Kernel] → [Hardware]

사용자     프로그램         인터페이스        운영체제        CPU/메모리/디스크
```

### OS 핵심 기능 5가지
1. 프로세스/스레드 관리 : 프로그램의 실행 단위 관리 (생성,종료,교체 등)
2. 메모리 관리 : RAM을 안전하고 효율적으로 분배, 가상 메모리 제공
3. 파일 시스템 : 하드디스크를 폴더/파일 형식으로 추상화
4. 입출력 제어 : 키보드, 마우스, 네트워크 등 입출력 장치와 연결
5. 보안 및 권한 : 사용자 권한, 접근 제어, 커널 보호 등

### 커널 모드 vs 사용자 모드
| 구분 | 설명 |
| --- | --- |
| 사용자 모드 | 일반 앱(크롬, 메모장 등), 직접 하드웨어 접근 X |
| 커널 모드 | OS 핵심 코드(파일 접근, 메모리 변경, 스케줄러 등) |
+ 시스템 콜을 통해 사용자 프로그램이 커널 기능을 요청함

### 프로세스와 스케줄링
+ 프로세스 : 실행 중인 프로그램 (메모리 + 상태 보유)
+ CPU는 한 번에 하나만 실행 -> 여러 프로세스를 번갈아 실행함
+ 이를 위한 기법 : 컨텍스트 스위칭
  + 앞서 배운 F-D-E 사이클에 `중간에 멈추고 다른 프로세스 시작`
+ 어떤 순서로 실행할지 정하는 것 : 스케줄러 알고리즘
  + FIFO, 라운드로빈, 우선순위 등

### 메모리 가상화
+ 프로그램은 자신만의 메모리를 쓰는 것처럼 착각함
  + 가상 주소 공간 제공
+ 실제 물리 주소는 OS가 매핑 관리함 -> 페이지 테이블로 변환
+ 이를 통해 보안도 유지, 효율도 개선

## 운영체제 2단계 : 사용자 모드와 커널 모드 - 왜 분리하는가?
### 왜 사용자 프로그렘에 제한을 둬야 할까?
+ 컴퓨터 자원은 모두가 공유해서 사용해야 한다
+ 만약 모든 프로그램이 CPU, 메모리, 디스크에 직접 접근한다면?
  + 메모리 충돌
  + 다른 프로그램의 데이터 훼손
  + 운영체제 코드까지 손상 -> 시스템 전체 다운

### 그래서 나온 개념: 보호 모드 (Protection Mode)
+ 운영 체제는 위험한 명령어는 특권 있는 상태에서만 실행되게 만듦

| 모드 | 설명 | 예시 |
| --- | --- | --- |
| User Mode | 일반 앱 실행, 제한된 권한 | 게임, 웹브라우저, VSCode |
| Kernel Mode | OS 핵심 코드 실행 가능 | 메모리 할당, 파일 시스템 제어 등 |

### 시스템 콜 = 사용자 -> 커널로 가는 "문"
+ 사용자 프로그램은 직접 커널에 접근 ❌
+ 대신 *시스템 콜*이라는 문을 통해 *OS에게 요청*
  + Ex. read(), write(), fork(), exec() 등

### 시스템 콜의 흐름 요약
```
[사용자 모드]
↓
→ 시스템 콜 발생 (ex. read())
↓
→ 모드 전환: 커널 모드 진입
↓
→ 커널 코드 실행 (디스크 접근 등)
↓
→ 작업 완료
↓
→ 사용자 모드로 복귀
```

## 컨텍스트 스위칭 - CPU는 누구의 말을 들어야 하지?
```
사용자 1이 크롬을 켜고, 사용자 2는 게임을 실행하고 있음
동시에 동작하는 것처럼 보이지만...
CPU는 한 순간에 하나의 작업만 수행 가능

그러면?
```
운영체제는 CPU가 지금 누구 말을 들어야 하는지 결정해야 함

### 운영체제는 "실행 중인 프로그램"을 프로세스 라고 부름
+ 실행 중인 각 프로그램은 고유한 상태 정보를 갖고 있다
+ 이 상태 정보는 다음과 같다
  + 레지스터 상태 : 변수값, 현재 위치
  + 프로그램 카운터 : 다음에 실행할 명령어 주소
  + 스택/힙 포인터 : 함수 호출, 메모리 참조
  + 메모리 맵 : 해당 프로세스의 주소 공간

### 이걸 통째로 저장하는 걸 "컨텍스트"라고 부름
+ 컨텍스트 (Context) = 프로세스의 상태 스냅샷
+ 이걸 저장/복원하는 과정이 바로 **컨텍스트 스위칭**

### 컨텍스트 스위칭 흐름도
```
[현재 프로세스 실행 중]
↓
I/O 대기 발생 or 타임 슬라이스 종료
↓
레지스터/카운터 등 상태 저장 (PCB에)
↓
다른 프로세스의 상태 복원 (다른 PCB에서)
↓
다른 프로세스 실행 시작
```
`PCB`(Process Control Block): 프로세스의 상태 정보를 담은 운영체제의 자료구조

### 왜 필요한가?
| 이유 | 설명 |
| --- | --- |
| 효율성 | CPU가 놀지 않게 하기 위해 (I/O 대기중 다른 일 함) |
| 공정성 | 여러 프로그렘에 CPU를 적절히 분배 |
| 멀티태스킹 효과 | 동시에 여러 작업이 되는 듯한 착각을 줌 |

### 성능 영향
**컨텍스트 스위칭은 공짜가 아니다**
+ 저장/복원에는 시간이 든다 -> *오버헤드 발생*
+ 너무 자주 스위칭하면 -> *성능 저하*
+ 그래서 좋은 스케줄러는 *스위칭 최소화* + *반응속도 유지*를 고려한다

## 스케줄링 알고리즘 - CPU는 누구에게 줄까?
### 누가 먼저 실행돼야 하지?
```
동시에 여러 개의 프로세스가 실행 대기 중
-> CPU는 한 번에 하나만 처리 가능
-> 운영체제가 선택 기준을 가져야 함
```
+ 이 기준이 바로 스케줄링 알고리즘

### 스케줄링이 발생하는 시점
+ 프로세스가 새로 생성될 때
+ I/O 끝나고 다시 준비 상태로 돌아올 때
+ 타임 슬라이스가 끝났을 때
+ 프로세스가 종료될 떄

### 스케줄링 알고리즘 종류 요약
| 알고리즘 | 설명 | 특징 |
| --- | --- | --- |
| FCFS<br>(First-Come First-Served) | 먼저 온 순서대로 | 단순, 비선점형, 긴 작업이 뒤를 맏음 (Convoy 효과) |
| SJF<br>(Shortest Job First) | 실행 시간이 짧은 순 | 평균 대기시간 최소, 실행 시간 예측이 어려움 |
| RR<br>(Round Robin) | 일정 시간만 주고 교체 | 선점형, 공정성 확보, 타임 슬라이스 중요 |
| Priority Scheduling | 우선순위 높은 것부터 | 우선순위 낮은 작업 이 굶을 수 있음 (Starbation) |
| Multilevel Queue | 큐를 여러 개로 나눠 처리 | 시스템/인터랙티브/배치 작업을 분리 운영 |


### 선점형 vs 비선점형
+ 비-선점형 : 한번 잡은면 끝날 때까지 수행
  + Ex. FCFS, SJF
+ 선점형 : 실행 중 다른 프로세스가 뺏을 수 있음
  + Ex. RR, Priority(선점형)

### 알고리즘 선택 기준
운영체제는 상황에 따라 다른 목표를 갖는다
+ 빠른 반응 속도 (인터랙티브 시스템)
+ 최대 처리량 (서버 시스템)
+ 최소 대기 시간 (배치 시스템)
+ 공정성
  + 알고리즘을 하나만 쓰는 게 아니라, 하이브리드로 쓰는 경우도 많다

## 가상 메모리 & 페이징 - "메모리가 부족한데도 프로그램이 돌아간다?"
```
RAM이 8GB인 컴퓨터에서 10GB짜리 프로그램을 어떻게 실행할 수 있을까?
```
+ 예전엔 불가능했다. 메모리가 부족하면 그냥 "메모리 부족 에러"
+ 현대 OS는 가능하다. 왜?
  + "가상 메모리"를 제공하기 때문

### 가상 메모리란?
+ 실제 메모리(RAM)의 크기와 관계없이 각 프로세스에게 거대한 메모리 공간이 있는 척 하게 해주는 기술
  + `추상화`, `메모리 보호`, `유연한 공간 제공`

### 가상 메모리의 핵심 기법: 페이징
왜 필요한가?
+ 가상 메모리를 실제 메모리에 대응시켜야 한다
+ 연속된 공간을 배치하기는 어렵다 -> 단위로 나눠서 배치하자!

### 페이징 구조 요약
| 개념 | 크기 단위 | 설명 |
| --- | --- | --- |
| Page | 보통 4KB | 가상 메모리의 고정 크기 블록 |
| Frame | 4KB | 실제 RAM의 고정 크기 블록 |
| 페이지 테이블 | - | 가상 주소 -> 실제 주소 매핑 관리 구조 |

### 페이징의 장점
+ 메모리를 작은 단위로 관리하므로 단편화 줄어든다
+ 연속된 공간 없이도 가상 메모리 제공 가능
+ 다른 프로세스 간 메모리 침범 방지

### 메모리 접근 흐름 요약
```
[프로그램 실행 → 가상 주소 생성]
↓
[CPU → MMU(Memory Management Unit)]
↓
[페이지 테이블 참조 → 실제 주소로 변환]
↓
[RAM에서 해당 데이터 참조 or 페이지 부재 → 디스크에서 불러오기]
```
+ 이 때 디스크에서 불러오는 걸 **페이지 스와핑(Page Fault)** 이라고 한다
  + 느리고 비용이 큼 -> 그래서 캐시처럼 잘 관리해야 한다

## 페이지 부재와 교체 알고리즘 - "RAM이 부족할 때 누구를 쫓아낼까?"
### Page Fault란?
CPU가 요청한 *가상 주소의 페이지*가 **RAM이 없을 때 발생하는 인터럽트**

#### 예시 흐름
```
1. CPU가 0xB004 주소 접근 시도
2. 페이지 테이블 확인 → RAM에 없음
3. → Page Fault 인터럽트 발생!
4. → 디스크에서 해당 페이지 로딩
5. → 페이지 테이블 갱신
6. → 다시 명령어 재시도
```
+ 이 과정은 느리다 - SSD, HDD 등 RAM보다 수십~수백 배 느림
  + 그래서 얼마나 잘 교체하느냐가 성능 핵심

### 페이지 교체는 왜 필요한가?
+ RAM은 유한하다
+ 모든 페이지를 동시에 올려놓을 순 없다
  + 새로운 페이지를 올릴 공간이 없다면?
    + 기존 페이지중 하나를 "퇴출"시켜야 한다
      + 이게 바로 **페이지 교체(Page Replacement)**

### 대표적인 페이지 교체 알고리즘
| 알고리즘 | 설명 | 특징 |
| --- | --- | --- |
| FIFO | 가장 먼저 들어온 페이지부터 제거 | 단순하지만 성능 나쁠 수 있음 (Belady's anomaly 발생 가능) |
| LRU<br>(Least Recently Used) | 가장 오랫동안 사용되지 않은 페이지 제거 | 성능 우수, 구현 어려움 (시간 or 스택 필요) |
| Optimal | 앞으로 가장 오래 쓰이지 않을 페이지 제거 | 이상적이지만 실제 구현 불가능 (예측 불가) |

## 운영체제 - 페이징 파트 마무리 정리
### 핵심 개념 요약
| 개념 | 정의 | 핵심 역할 |
| --- | --- | --- |
| Page | 가상 메모리의 고정 크기 블록 | 가상 주소 공간 구성 |
| Frame | 실제 메모리(RAM)의 고정 크기 블록 | 실제 저장 공간 |
| 페이지 테이블 | 페이지 번호 -> 프레임 번호 매핑 구조 | 주소 변환용 정보 저장 |
| 페이지 폹 | 요청한 페이지가 RAM에 없을 때 발생 | 디스크에서 적재 필요 |
| 페이지 교체 | RAM이 꽉 찼을 때 기존 페이지를 제거 | 새로운 페이지 적재 가능하게 함 |

### 전체 흐름 요약
```
[1] CPU가 가상 주소 접근
↓
[2] MMU가 페이지 번호 추출
↓
[3] 페이지 테이블 조회 → Valid Bit 확인
↓
[4] 
  - 있으면 → 프레임 매핑 → RAM에서 읽음
  - 없으면 → 페이지 폴트 → 디스크에서 로딩
↓
[5] RAM에 빈 프레임 없으면 → 페이지 교체 알고리즘 실행
↓
[6] 페이지 적재 및 페이지 테이블 갱신
↓
[7] 명령어 재시도
```

## TBL: 주소 변환 캐시 시스템
```
페이지 테이블은 주소 변환 매핑 정보를 담고 있다
하지만 페이지 테이블은 RAM에 저장된 자료구조다
→ 즉, 가상 주소 접근할 때마다 매번 RAM 접근이 필요
→ 빠르게 하려고 했더니 오히려 느림!
```

### 해결책: MMU 안에 TBL 캐시를 둔다
+ TLB(Translation Lookaside Buffer)는 CPU 내 MMU에 위치한 페이지 테이블의 일부를 캐싱한 고속 메모리

| 특징 | 설명 |
| --- | --- |
| 위치 | MMU (Memory Management Unit) 내부 |
| 역할 | 최근 사용된 페이지 번호 ↔ 프레임 번호 매핑 저장 |
| 형태 | 보통 16 ~ 512개 수준의 소형 캐시<br>(완전 연관 방식) |

### 주소 변환 흐름 (TLB 포함)
```
1. CPU가 가상 주소 접근 (ex. 0xB004)
2. MMU가 Page 번호 추출 → TLB에 있는지 먼저 확인

   [TLB Hit] → 바로 프레임 번호 얻음 → RAM 접근
   [TLB Miss] → 페이지 테이블에서 찾아서 RAM 접근
               → 동시에 TLB에 해당 항목 캐싱

```
+ TLB는 **주소 변환 캐시**라고 보면 된다
  + 빠르면 단 1~2 사이클
  + Miss 시엔 페이지 테이블 "Page Walk"발생

### TLB의 장점
+ 주소 변환 속도 획기적으로 개선
+ 페이지 테이블 전체를 접근할 필요가 없다
+ 지역성 특성과 잘 맞음 (최근 쓰인 페이지를 또 쓸 확률 높음)

### TLB의 한계
| 상황 | 결과 |
| --- |----|
| TLB Miss | 페이지 테이블 접근 → 느림 |
| 문맥 교환 시 | 다른 프로세스의 페이지 테이블 매핑이 TLB에 있을 수 있다 -> TLB Flush 필요 |
| 다단계 페이지 테이블 구조 | → TLB Miss시 더욱 많은 페이지 워크 발생 가능 |

#### TLB에 대한 보충
+ CPU 내 MMU 내부에서 작동하는 고속 캐시 구조다
+ TLB Hit 시 빠른 변환이 가능
  + Miss가 발생하면 RAM에 있는 페이지 테이블까지 접근해야 하므로 성능 저하
+ 문맥 전환이 발생할 경우 프로세스별 페이지 매핑이 달라 TLB를 초기화해야 하는 단점
+ 