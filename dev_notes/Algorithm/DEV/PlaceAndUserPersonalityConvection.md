# 데이터 수렴 문제를 해결하는 성향 업데이트 로직 설계

사용자와 여행지의 정체성을 정의하는 과정에서 발생하는 **통계적 수렴 문제**를 해결하고, 데이터의 해상도를 높이기 위해 설계한 '**선택적 성향 업데이트 로직**'을 공유합니다.

---

## 1. 성향 정의의 근거: OCEAN 모델의 도입
사용자와 여행지의 정체성을 정의하기 위해서는 정량화된 지표가 필요했습니다. 단순 선호도 조사를 넘어 개인의 심리적 기저를 가장 잘 나타내는 **OCEAN(Big 5) 모델**을 도입하여, 각 객체를 5차원의 벡터 데이터(**0~10점**)로 치환했습니다.

* **Openness (개방성):** 새로운 경험에 대한 수용도
* **Conscientiousness (성실성):** 계획적이고 체계적인 성향
* **Extraversion (외향성):** 타인과의 상호작용 및 활동성
* **Agreeableness (우호성):** 타인에 대한 협력적 태도
* **Neuroticism (신경성):** 환경 변화에 대한 민감도

> **참고 문헌:** [McCrae & Costa (1987) - Validation of the five-factor model of personality](https://psycnet.apa.org/record/1987-11119-001)

## 2. 발생한 문제: 데이터 무색무취화 (평균 회귀 경향)
초기 모델은 상호작용 발생 시 5차원 벡터 전체를 일괄 업데이트하는 구조였습니다. 그러나 데이터 업데이트 과정에서 모든 차원이 균등하게 수렴하면 개별 특성이 사라지는 **평균 회귀 경향 (Regression to the mean)** 현상이 발생했습니다. 변별력이 소실된 데이터를 방지하기 위해 **연산의 선택성**과 **방어 기제**라는 두 가지 개념을 도입했습니다.

* **관련 개념:** [Central Limit Theorem - Wolfram MathWorld](https://mathworld.wolfram.com/CentralLimitTheorem.html)
---

## 3. 로직의 재설계: 객체 정의의 전환과 피드백의 정교화

### 3.1. 객체 역할의 분리: '개인'과 '집합체'
사용자와 여행지는 데이터의 성격이 근본적으로 다릅니다.

* **사용자(User):** 주관적인 취향과 개인화된 특이성을 가진 **'동적 객체'**
* **여행지(Place):** 수많은 방문객의 경험이 누적되어 정의되는 **'정적 집합체'**
> **근거:** 여행지가 특정 사용자에 의해 실시간으로 변한다면 정보의 일관성이 깨집니다. 따라서 여행지는 다수의 투표를 통해 객관화되는 **집단지성 기반의 정적 모델**로 정의합니다.

### 3.2. 감정 이분법(좋아요/별로예요)의 도입
체류 시간 등 간접 지표의 왜곡을 방지하기 위해 **명시적 피드백(Explicit Feedback)**을 도입했습니다.
* **방향성의 획득:** 이 선택은 업데이트 수식에서 닮아갈 것인가(긍정), 혹은 멀어질 것인가(부정)를 결정하는 결정적인 파라미터가 됩니다.

### 3.3. 연산 대상의 희소성 활용
"무엇 때문에?"라는 해상도 높은 데이터를 위해 **선택적 피처 추출(Sparse Feature Extraction)** 개념을 도입했습니다.
* OCEAN 전체를 건드리는 대신, 사용자가 선택한 **1~3개의 특정 키워드**에만 주목합니다.
* 예: "시끄러워서 별로예요" → '외향성' 차원만 연산, 나머지 노이즈 제거.
* **관련 개념:** [Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html)
---

## 4. 성향 업데이트 공식

확고한 취향일수록 변화에 저항하는 **디펜스 팩터(Defense Factor)** 로직을 적용합니다. 이는 공학의 신호 처리 과정에서 노이즈를 필터링하는 원리와 같습니다.

$$u_{t+1} = u_t + \delta(p_t - u_t) \times L \times \left( 1 - \frac{|u_t - 5.0|}{5.0} \times D \right)$$

* **$\delta$ (방향성):** 키워드 선택을 통해 도출된 타겟 방향입니다. 만족 여부에 따라 정체성을 강화하거나 수정합니다.
* **$L$ (학습률):** 약 30~50회의 유효 시행을 통해 통계적 유의성을 확보하도록 설계된 시정수입니다.
* **방어 계수(Defense Factor):** 현재 점수가 극단(0 또는 10)에 가까울수록, 즉 성향의 **분산(Variance)**이 클수록 외부 자극에 대한 저항치를 높여 항상성을 유지합니다.

### [수학적 증명 및 파라미터 근거]

#### ① 분산 거리의 정규화 ($d_{norm}$)
분산 및 거리값의 정규화 (Normalization)수식 내의 $|u_t - 5.0| / 5.0$ 항은 사용자의 성향이 중심(무색무취)으로부터 얼마나 떨어져 있는지를 0에서 1 사이의 값으로 치환하는 과정입니다.

* **증명:**
OCEAN 점수 범위 $S = [0, 10]$ 일 때, 평균 $\mu = 5.0$ 입니다.
임의의 점수 $x$에 대하여 중심과의 거리 $d = |x - 5.0|$ 의 최댓값은 $x$가 $0$ 또는 $10$일 때의 $5.0$입니다.
따라서 $d_{norm} = \frac{|x - 5.0|}{5.0}$ 을 통해 모든 거리를 $[0, 1]$ 구간으로 압축함으로써, **성향의 강도(Intensity)**를 확률적 가중치로 사용할 수 있게 됩니다.
이는 서로 다른 차원 간의 변화량을 동일한 스케일에서 비교하기 위한 필수적인 선행 조건입니다.

#### ② 학습률 $L = 0.05$의 통계적 증명 (EMA 응답 공식) ([EMA 수렴 공식 문서](https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average))
* **가정:** 90% 신뢰도($\epsilon=0.1$) 도달을 위해 유효 시행 횟수($n$) 45회 설정.
* **증명:** 지수 이동 평균의 수렴 공식 $(1-L)^n = \epsilon$에 대입.
  $$(1-L)^{45} = 0.1 \implies 45 \ln(1-L) = \ln(0.1)$$
  $$\ln(1-L) \approx -0.0511 \implies 1-L \approx 0.9502$$
  $$\therefore \mathbf{L \approx 0.05}$$
* **결론:** $L=0.05$는 사용자가 45회의 경험을 통해 자신의 성향을 시스템에 90% 일치시킬 수 있는 최적의 학습 속도입니다.

#### ③ 방어 계수 $D = 0.4$의 산출 원리
* **가정:** 방어 계수를 연산하기 위한 도식에서의 분산은 정규화를 통해 [0,1] 범위를 상정할 수 있기에 전기공학 요소의 연산도 가능합니다.
* **목표:** 극단값에 도달한 성향 점수는 사용자의 취향으로 판단하기 위한 수단이자 평균 회귀 경향을 극복하기 위한 보조수단 확립
* **증명:** $1 - (d_{norm} \times D) \ge 0.6$ 에서 $d_{norm}=1$일 때 $D \le 0.4$ 도출.
* **통계적 근거:**  **"신뢰도 이론(Credibility Theory) 및 신호 제어의 감쇠 계수(Attenuation Factor) 원리를 적용하여, 극단적 피드백에 의한 점수 왜곡을 방지하고 시스템 수렴성을 확보하기 위해 $D$를 0.4로 제한함"**

---

## 5. 여행지 데이터 모델링: 집단지성 기반

### 5.1. 여행지 점수 산출 공식
여행지의 최종 점수 $P_n$은 시스템 기본값과 유저 피드백의 가중 합산으로 결정됩니다.

$$P_n = (1 - w) \cdot p_{init} + w \cdot \left( \frac{\text{TraitConfirmedCount}_n}{\text{TotalInteractionCount}_n} \times 10 \right)$$

* **$p_{init}$ (초기값):** TourAPI 카테고리를 OCEAN 성향으로 매핑한 기초 점수.
* **$\text{TraitConfirmedCount}_n$ (속성 증명 횟수):** * 긍정 증명: 외향인이 "활기차다"고 만족한 경우 (**+1.0** 반영)
    * 부정 증명: 내향인이 "시끄럽다"고 불만족한 경우 (**+0.4** 반영)

### 5.2. 데이터 신뢰도 가중치 ($w$)
사용자 피드백이 반영되는 비중을 데이터 양에 따라 조절합니다.

$$w = \min\left(\frac{\text{TotalCount}_n}{50}, 1.0\right)$$

방문자가 늘어날수록 시스템 초기값의 비중은 줄어들며, 50명에 도달하는 순간 오직 **집단지성**으로만 정체성이 정의됩니다.

### 5.3. 부정 피드백의 보수적 반영 (0.4x)
부정 피드백은 외부 요인(날씨, 컨디션 등)에 의한 노이즈일 확률이 높습니다. 이를 방지하기 위해 긍정 신호는 100% 반영하되, **부정 신호는 신뢰도를 40%로 제한**하여 데이터 안정성을 확보합니다.
* **통계적 근거:** [Bayes' Theorem](https://plato.stanford.edu/entries/bayes-theorem/)에 근거하여 보정합니다.
---

## 6. 결론
이번 로직 설계의 핵심은 "**선택과 집중**"입니다. 사용자가 강조한 특정 성향에 연산을 집중하여 희소성 문제를 해결하고, 공학적 저항 수식을 통해 통계적 수렴(평균 회귀 경향 및 벡터 수축)을 극복했습니다. 이를 통해 우리 서비스는 유저의 성향 점수를 단순한 숫자가 아닌, 확고한 '**취향**'으로 기록해 나갈 것입니다.